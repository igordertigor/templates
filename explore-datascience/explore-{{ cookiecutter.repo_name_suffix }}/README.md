# Welcome to explore-{{ cookiecutter.repo_name_suffix }}

This is an autogenerated readme with some information on how to get started. You may want to replace this initial text with a more meaningful description.


## Directory structure

There are four relevant folders here:

1. `data/` contains your data. Typically, you would have scripts moving data from the `data/raw/` subfolder to the `data/processed/` and finally to the `data/final/` subfolder. If you train directly on raw data you can ignore that part. However, it is probably a good idea to keep the folder structure
2. `src/` this is where your code goes. For most datascience projects (in particular with DVC) there are two classes of code. Some code is scripts that you run to transform one dataset to another and some code is concerned with visualizations (in DVC often [vega-lite](https://vega.github.io/vega-lite/) specifications). So there are two separate subfolders for these two kinds of code. Note also, that neither of these is importable as a python package. The main reason for that is that shared code may make your DVC pipelines quite difficult to maintain. If you really need shared code, add a separate folder `src/shared/` with a file `src/shared/__init__.py` and have your shared code there. Make sure that you maintain the pipeline dependencies in that case.
3. `.dvc/` is an internal DVC folder. It contains your DVC-cache and DVC configuration files.
4. `.mlem/` is an internal folder for mlem. It contains artifacts that you stored using `mlem.api.save`. See below for details.

## Using DVC

This project uses [data version control](https://dvc.org). Here are some key points that follow from that:

- Separate *storage option for large files*. Use `dvc add <SOMETHING>` to add files or folders to DVC. This is usually helpful for files that are too large to keep in version control, for binary files and sometimes also for small data files. If you add a file to DVC, then DVC creates an extra file by the same name, but with a `.dvc`-extension. The `.dvc`-file should be committed to git. {% if cookiecutter.dvc_remote_storage %}This project uses DVC remote storage. When you use `dvc add`, files will be added to your *local* DVC storage. If you are working with others, they will not have access to those files. Use `dvc push` to also push the files to the remote.{% endif %}
- *Lightweight pipelines* can be defined using either `dvc run` or in the `dvc.yaml` file. Use them as much as possible. Having a pipeline defined saves you from a lot of headache. Plus you can run all the scripts that have changes with a simple `dvc repro`. You can find more information about DVC pipelines [here](https://dvc.org/doc/command-reference/run) and [here](https://dvc.org/doc/user-guide/project-structure/dvcyaml-files).
- Make use of the central `params.yaml` file to store all your project's parameters and read them into your scripts. Parameters in `params.yaml` can be specified in pipelines.


## Store models using mlem

This project has [mlem](https://mlem.ai) set up. Use it to store your models like this (replace the relevant parts):
```python
import mlem.api

mlem.api.save(yourmodelpythonobjecthere, 'yourmodelnamehere')
```
If you need to load a model from this project, you can do so using `mlem.api.load('yourmodelnamehere')`.

Mlem will put the models that you save into a subfolder in the `.mlem/` directory. Each model consists of two (or more) files, one file with an `.mlem` extension, which can be tracked by git, and one (or more) without an extension. For this project, mlem is configured to support model storage with dvc. However, you still need to manually add the model to dvc. Only do that for the files without extension.

Having artifacts stored with mlem will allow loading them directly from this repository for production setups.
